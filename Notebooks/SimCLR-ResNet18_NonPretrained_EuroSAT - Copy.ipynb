{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd2eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# =============================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Torchvision Version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable to use GPU 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Now import torch\n",
    "import torch\n",
    "\n",
    "# Your code will now only see GPU 1. \n",
    "# torch.cuda.current_device() will return 0, as it's the first *visible* device.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafdb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. SETUP AND CONFIGURATION\n",
    "# =============================================================================\n",
    "# Hyperparameters\n",
    "NUM_EPOCHS = 100 # SSL requires more epochs than supervised learning\n",
    "BATCH_SIZE = 1024 # Crucial for contrastive learning to have a large batch size\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "TEMPERATURE = 0.5 # Temperature for the NT-Xent loss\n",
    "PROJECTION_DIM = 128 # Dimension of the projected features\n",
    "\n",
    "# # Set the device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "# # Note: A BATCH_SIZE of 256 might be tight on a 4GB GPU. If you get a CUDA out-of-memory\n",
    "# # error, try reducing it to 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024842c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. DATA AUGMENTATION AND LOADING\n",
    "# =============================================================================\n",
    "# Define the strong augmentations for SimCLR\n",
    "# We apply these transforms twice to get two correlated views of the same image.\n",
    "class SimCLRAugmentation:\n",
    "    def __init__(self, size):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=size),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
    "            ], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Return two different augmented views of the same image\n",
    "        return self.transform(x), self.transform(x)\n",
    "\n",
    "# Load the EuroSAT dataset and apply the augmentations\n",
    "# The dataset will be downloaded to a 'Data' directory.\n",
    "train_dataset = torchvision.datasets.EuroSAT(\n",
    "    root='./Data',\n",
    "    download=True,\n",
    "    transform=SimCLRAugmentation(size=64) # EuroSAT images are 64x64\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True # Drop the last incomplete batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10634e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. MODEL ARCHITECTURE (ENCODER + PROJECTOR)\n",
    "# =============================================================================\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_encoder, projection_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = base_encoder\n",
    "        self.encoder.fc = nn.Identity() # Replace the classifier layer\n",
    "\n",
    "        # Projector head\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, 512, bias=False), # ResNet-18 has 512 output features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, projection_dim, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.projector(h)\n",
    "        return h, z\n",
    "\n",
    "# Initialize the model\n",
    "base_encoder = resnet18()\n",
    "model = SimCLR(base_encoder, projection_dim=PROJECTION_DIM).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73137659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. LOSS FUNCTION AND OPTIMIZER\n",
    "# =============================================================================\n",
    "# NT-Xent Loss Function\n",
    "def nt_xent_loss(z1, z2, temperature):\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    \n",
    "    # Concatenate the projections for calculating similarity matrix\n",
    "    z = torch.cat([z1, z2], dim=0)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    sim_matrix = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=2)\n",
    "    \n",
    "    # Get the positive samples (the other view of the same image)\n",
    "    # The matrix is 2N x 2N, positives are at (i, i+N) and (i+N, i)\n",
    "    sim_ij = torch.diag(sim_matrix, BATCH_SIZE)\n",
    "    sim_ji = torch.diag(sim_matrix, -BATCH_SIZE)\n",
    "    positives = torch.cat([sim_ij, sim_ji], dim=0)\n",
    "    \n",
    "    # Mask to remove self-similarity\n",
    "    mask = (~torch.eye(2 * BATCH_SIZE, 2 * BATCH_SIZE, dtype=bool)).float().to(device)\n",
    "    \n",
    "    # Denominator: sum of similarities with all other samples\n",
    "    numerator = torch.exp(positives / temperature)\n",
    "    denominator = mask * torch.exp(sim_matrix / temperature)\n",
    "    \n",
    "    loss = -torch.log(numerator / torch.sum(denominator, dim=1))\n",
    "    return torch.mean(loss)\n",
    "\n",
    "# LARS Optimizer is often recommended for SimCLR, but AdamW works well too.\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader)*NUM_EPOCHS, eta_min=0, last_epoch=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. PRE-TRAINING LOOP\n",
    "# =============================================================================\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    for (view1, view2), _ in pbar: # We don't need the labels here\n",
    "        view1, view2 = view1.to(device), view2.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        _, z1 = model(view1) # h1 is the representation, z1 is the projection\n",
    "        _, z2 = model(view2)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = nt_xent_loss(z1, z2, TEMPERATURE)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': loss.item(), 'lr': scheduler.get_last_lr()[0]})\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Finished Pre-training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. SAVE THE ENCODER (BACKBONE)\n",
    "# =============================================================================\n",
    "# After pre-training, we only need the encoder part.\n",
    "torch.save(model.encoder.state_dict(), 'simclr_encoder_eurosat.pth')\n",
    "print(\"Encoder saved to simclr_encoder_eurosat.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4399362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# =============================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# =============================================================================\n",
    "# 2. SETUP AND CONFIGURATION\n",
    "# =============================================================================\n",
    "# Hyperparameters for linear evaluation\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.01\n",
    "TRAIN_FRACTION = 0.1  # <-- We will use only 10% of the available training data\n",
    "TEST_FRACTION = 0.2   # <-- Hold out 20% of the total data for the final test set\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. DATA LOADING (Supervised with Small Labeled Set)\n",
    "# =============================================================================\n",
    "# Use standard, simpler augmentations for evaluation\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the full dataset to start\n",
    "full_dataset = torchvision.datasets.EuroSAT(root='./data', download=True, transform=eval_transforms)\n",
    "class_names = full_dataset.classes\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(f\"Total images in dataset: {len(full_dataset)}\")\n",
    "\n",
    "# --- Correct Splitting Logic ---\n",
    "# 1. Split the dataset into a training pool and a final test set\n",
    "num_total = len(full_dataset)\n",
    "num_test = int(TEST_FRACTION * num_total)\n",
    "num_train_pool = num_total - num_test\n",
    "\n",
    "train_pool_dataset, test_dataset = random_split(\n",
    "    full_dataset, \n",
    "    [num_train_pool, num_test],\n",
    "    generator=torch.Generator().manual_seed(42) # for reproducibility\n",
    ")\n",
    "print(f\"Size of training pool: {len(train_pool_dataset)}\")\n",
    "print(f\"Size of test set: {len(test_dataset)}\")\n",
    "\n",
    "# 2. Use only a small fraction of the training pool for actual training\n",
    "num_train_subset = int(TRAIN_FRACTION * len(train_pool_dataset))\n",
    "train_indices = np.random.choice(len(train_pool_dataset), num_train_subset, replace=False)\n",
    "train_subset_dataset = Subset(train_pool_dataset, train_indices)\n",
    "\n",
    "print(f\"Using {len(train_subset_dataset)} images for training the linear classifier ({TRAIN_FRACTION*100:.0f}% of the training pool).\")\n",
    "\n",
    "# 3. Create DataLoaders\n",
    "train_loader = DataLoader(train_subset_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. MODEL FOR LINEAR EVALUATION\n",
    "# =============================================================================\n",
    "# Load the pre-trained encoder\n",
    "encoder = resnet18()\n",
    "encoder.fc = nn.Identity() # We don't need the original classifier\n",
    "encoder.load_state_dict(torch.load('simclr_encoder_eurosat.pth'))\n",
    "print(\"Pre-trained encoder loaded successfully.\")\n",
    "\n",
    "# Freeze all the parameters in the encoder\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Create the full model with a new linear classifier\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, encoder, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = LinearClassifier(encoder, NUM_CLASSES).to(device)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. LOSS, OPTIMIZER, AND TRAINING\n",
    "# =============================================================================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training\n",
    "    model.train()\n",
    "    model.encoder.eval()\n",
    "    \n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Testing\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Test]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Finished Linear Evaluation on the held-out test set.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
