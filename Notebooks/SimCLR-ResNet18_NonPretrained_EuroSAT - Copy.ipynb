{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd2eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# =============================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Torchvision Version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafdb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. SETUP AND CONFIGURATION\n",
    "# =============================================================================\n",
    "# Hyperparameters\n",
    "NUM_EPOCHS = 100 # SSL requires more epochs than supervised learning\n",
    "BATCH_SIZE = 1024 # Crucial for contrastive learning to have a large batch size\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "TEMPERATURE = 0.5 # Temperature for the NT-Xent loss\n",
    "PROJECTION_DIM = 128 # Dimension of the projected features\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# Note: A BATCH_SIZE of 256 might be tight on a 4GB GPU. If you get a CUDA out-of-memory\n",
    "# error, try reducing it to 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024842c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. DATA AUGMENTATION AND LOADING\n",
    "# =============================================================================\n",
    "# Define the strong augmentations for SimCLR\n",
    "# We apply these transforms twice to get two correlated views of the same image.\n",
    "class SimCLRAugmentation:\n",
    "    def __init__(self, size):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=size),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
    "            ], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Return two different augmented views of the same image\n",
    "        return self.transform(x), self.transform(x)\n",
    "\n",
    "# Load the EuroSAT dataset and apply the augmentations\n",
    "# The dataset will be downloaded to a 'Data' directory.\n",
    "train_dataset = torchvision.datasets.EuroSAT(\n",
    "    root='./Data',\n",
    "    download=True,\n",
    "    transform=SimCLRAugmentation(size=64) # EuroSAT images are 64x64\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True # Drop the last incomplete batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10634e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. MODEL ARCHITECTURE (ENCODER + PROJECTOR)\n",
    "# =============================================================================\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_encoder, projection_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = base_encoder\n",
    "        self.encoder.fc = nn.Identity() # Replace the classifier layer\n",
    "\n",
    "        # Projector head\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, 512, bias=False), # ResNet-18 has 512 output features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, projection_dim, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.projector(h)\n",
    "        return h, z\n",
    "\n",
    "# Initialize the model\n",
    "base_encoder = resnet18()\n",
    "model = SimCLR(base_encoder, projection_dim=PROJECTION_DIM).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73137659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. LOSS FUNCTION AND OPTIMIZER\n",
    "# =============================================================================\n",
    "# NT-Xent Loss Function\n",
    "def nt_xent_loss(z1, z2, temperature):\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    \n",
    "    # Concatenate the projections for calculating similarity matrix\n",
    "    z = torch.cat([z1, z2], dim=0)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    sim_matrix = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=2)\n",
    "    \n",
    "    # Get the positive samples (the other view of the same image)\n",
    "    # The matrix is 2N x 2N, positives are at (i, i+N) and (i+N, i)\n",
    "    sim_ij = torch.diag(sim_matrix, BATCH_SIZE)\n",
    "    sim_ji = torch.diag(sim_matrix, -BATCH_SIZE)\n",
    "    positives = torch.cat([sim_ij, sim_ji], dim=0)\n",
    "    \n",
    "    # Mask to remove self-similarity\n",
    "    mask = (~torch.eye(2 * BATCH_SIZE, 2 * BATCH_SIZE, dtype=bool)).float().to(device)\n",
    "    \n",
    "    # Denominator: sum of similarities with all other samples\n",
    "    numerator = torch.exp(positives / temperature)\n",
    "    denominator = mask * torch.exp(sim_matrix / temperature)\n",
    "    \n",
    "    loss = -torch.log(numerator / torch.sum(denominator, dim=1))\n",
    "    return torch.mean(loss)\n",
    "\n",
    "# LARS Optimizer is often recommended for SimCLR, but AdamW works well too.\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader)*NUM_EPOCHS, eta_min=0, last_epoch=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. PRE-TRAINING LOOP\n",
    "# =============================================================================\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    for (view1, view2), _ in pbar: # We don't need the labels here\n",
    "        view1, view2 = view1.to(device), view2.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        _, z1 = model(view1) # h1 is the representation, z1 is the projection\n",
    "        _, z2 = model(view2)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = nt_xent_loss(z1, z2, TEMPERATURE)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': loss.item(), 'lr': scheduler.get_last_lr()[0]})\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Finished Pre-training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. SAVE THE ENCODER (BACKBONE)\n",
    "# =============================================================================\n",
    "# After pre-training, we only need the encoder part.\n",
    "torch.save(model.encoder.state_dict(), 'simclr_encoder_eurosat.pth')\n",
    "print(\"Encoder saved to simclr_encoder_eurosat.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4399362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# =============================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# 2. SETUP AND CONFIGURATION\n",
    "# =============================================================================\n",
    "# Hyperparameters for linear evaluation\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. DATA LOADING (Supervised)\n",
    "# =============================================================================\n",
    "# Use standard, simpler augmentations for evaluation\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "full_dataset = torchvision.datasets.EuroSAT(root='./data', download=True, transform=eval_transforms)\n",
    "class_names = full_dataset.classes\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# =============================================================================\n",
    "# 4. MODEL FOR LINEAR EVALUATION\n",
    "# =============================================================================\n",
    "# Load the pre-trained encoder\n",
    "encoder = resnet18()\n",
    "encoder.fc = nn.Identity() # We don't need the original classifier\n",
    "encoder.load_state_dict(torch.load('simclr_encoder_eurosat.pth'))\n",
    "print(\"Pre-trained encoder loaded successfully.\")\n",
    "\n",
    "# Freeze all the parameters in the encoder\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Create the full model with a new linear classifier\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, encoder, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        # The new classifier layer is the only part that will be trained\n",
    "        self.classifier = nn.Linear(512, num_classes) # ResNet-18 output is 512\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = LinearClassifier(encoder, NUM_CLASSES).to(device)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. LOSS, OPTIMIZER, AND TRAINING\n",
    "# =============================================================================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# We only pass the parameters of the classifier to the optimizer\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training\n",
    "    model.train()\n",
    "    # The encoder is in eval mode to disable batch norm updates\n",
    "    model.encoder.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Val]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {running_loss/len(train_loader):.4f}, Val Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Finished Linear Evaluation.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
