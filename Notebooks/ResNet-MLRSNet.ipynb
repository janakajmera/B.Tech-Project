{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954682ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORTS\n",
    "# =============================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Torchvision Version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c528265",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf44e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable to use GPU 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # set up according to whatever gpu is available\n",
    "\n",
    "# Now import torch\n",
    "import torch\n",
    "\n",
    "# Your code will now only see GPU 1. \n",
    "# torch.cuda.current_device() will return 0, as it's the first *visible* device.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbede301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. CONFIGURATION\n",
    "# =============================================================================\n",
    "# --- Experiment Settings ---\n",
    "MODELS_TO_TEST = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
    "# Note: Deeper models like resnet101/152 will require significant VRAM and time.\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "NUM_EPOCHS = 10 # seems like a fair compromise\n",
    "BATCH_SIZE = 256 # Just because I can\n",
    "LEARNING_RATE = 1e-3\n",
    "HF_DATASET_NAME = \"jonathan-roberts1/MLRSNet\"\n",
    "\n",
    "# --- Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf07d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. DATA LOADING & ANALYSIS\n",
    "# =============================================================================\n",
    "# --- Load Dataset ---\n",
    "print(\"Loading dataset from Hugging Face Hub...\")\n",
    "full_dataset = load_dataset(HF_DATASET_NAME)\n",
    "class_names = full_dataset['train'].features['label'].feature.names\n",
    "NUM_CLASSES = len(class_names)\n",
    "\n",
    "# --- 1. CLASS FREQUENCY ANALYSIS ---\n",
    "print(\"\\nAnalyzing class distribution...\")\n",
    "class_counts = np.zeros(NUM_CLASSES)\n",
    "for example in tqdm(full_dataset['train'], desc=\"Counting classes\"):\n",
    "    for label_index in example['label']:\n",
    "        class_counts[label_index] += 1\n",
    "\n",
    "# Create a pandas DataFrame for nice printing\n",
    "freq_df = pd.DataFrame({\n",
    "    'Class Name': class_names,\n",
    "    'Count': class_counts\n",
    "}).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Class Distribution in MLRSNet:\")\n",
    "print(freq_df)\n",
    "\n",
    "# --- Split and Transform Data ---\n",
    "split_dataset = full_dataset['train'].train_test_split(test_size=0.15, seed=42) # 85% train, 15% test- seed = 42 for reproducibility\n",
    "dataset = split_dataset\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "]) # Standard normalization for pre-trained models\n",
    "\n",
    "def apply_transforms(batch):\n",
    "    batch['pixel_values'] = [image_transforms(image.convert(\"RGB\")) for image in batch['image']]\n",
    "    multi_hot_labels = []\n",
    "    for label_indices in batch['label']:\n",
    "        new_label = torch.zeros(NUM_CLASSES)\n",
    "        new_label[label_indices] = 1.0\n",
    "        multi_hot_labels.append(new_label)\n",
    "    batch['label'] = torch.stack(multi_hot_labels)\n",
    "    del batch['image']\n",
    "    return batch\n",
    "\n",
    "dataset.set_transform(apply_transforms)\n",
    "\n",
    "# --- Create DataLoaders ---\n",
    "train_loader = DataLoader(dataset['train'], batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(dataset['test'], batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "print(\"\\nDataLoaders created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb0e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. MODEL TRAINING & EVALUATION\n",
    "# =============================================================================\n",
    "# --- Helper Functions ---\n",
    "def get_model(model_name, num_classes):\n",
    "    \"\"\"Loads a pre-trained ResNet model and replaces the classifier.\"\"\"\n",
    "    if model_name == 'resnet18':\n",
    "        model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "    elif model_name == 'resnet34':\n",
    "        model = models.resnet34(weights='IMAGENET1K_V1')\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "    elif model_name == 'resnet101':\n",
    "        model = models.resnet101(weights='IMAGENET1K_V1')\n",
    "    elif model_name == 'resnet152':\n",
    "        model = models.resnet152(weights='IMAGENET1K_V1')\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not supported.\")\n",
    "        \n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "def calculate_metrics(preds, targets, threshold=0.5):\n",
    "    preds = torch.sigmoid(preds)\n",
    "    binary_preds = (preds >= threshold).cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "    f1 = f1_score(targets, binary_preds, average='samples', zero_division=0)\n",
    "    precision = precision_score(targets, binary_preds, average='samples', zero_division=0)\n",
    "    recall = recall_score(targets, binary_preds, average='samples', zero_division=0)\n",
    "    accuracy = accuracy_score(targets, binary_preds)\n",
    "    return {'accuracy': accuracy, 'f1': f1, 'precision': precision, 'recall': recall}\n",
    "\n",
    "# --- Main Experiment Loop ---\n",
    "results = {}\n",
    "\n",
    "for model_name in MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Training {model_name.upper()} {'='*20}\")\n",
    "    \n",
    "    # Initialize model, loss, and optimizer\n",
    "    model = get_model(model_name, NUM_CLASSES)\n",
    "    criterion = nn.BCEWithLogitsLoss() # Suitable for multi-label classification - cannot use CrossEntropyLoss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE) # Adam optimizer generally works well (can try with other optimizers too)\n",
    "\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_f1': [], 'val_precision': [], 'val_recall': [], 'val_accuracy': []}\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"):\n",
    "            inputs, labels = batch['pixel_values'].to(device), batch['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_train_loss = running_loss / len(dataset['train'])\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Val]\"):\n",
    "                inputs, labels = batch['pixel_values'].to(device), batch['labels'].to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                all_preds.append(outputs)\n",
    "                all_targets.append(labels)\n",
    "        \n",
    "        epoch_val_loss = val_loss / len(dataset['test'])\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        \n",
    "        # Calculate metrics for the epoch\n",
    "        all_preds_tensor = torch.cat(all_preds, dim=0)\n",
    "        all_targets_tensor = torch.cat(all_targets, dim=0)\n",
    "        val_metrics = calculate_metrics(all_preds_tensor, all_targets_tensor)\n",
    "        \n",
    "        history['val_f1'].append(val_metrics['f1'])\n",
    "        history['val_precision'].append(val_metrics['precision'])\n",
    "        history['val_recall'].append(val_metrics['recall'])\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} -> Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f} | Val F1: {val_metrics['f1']:.4f}\")\n",
    "\n",
    "    results[model_name] = history\n",
    "    print(f\"Finished training for {model_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1417ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. RESULTS VISUALIZATION\n",
    "# =============================================================================\n",
    "print(\"\\nVisualizing results...\")\n",
    "\n",
    "# --- 2. PLOT LOSS CURVES ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 7))\n",
    "\n",
    "for model_name, history in results.items():\n",
    "    ax1.plot(range(1, NUM_EPOCHS + 1), history['val_loss'], 'o-', label=f'{model_name} Val Loss')\n",
    "\n",
    "ax1.set_title('Validation Loss Comparison Across ResNet Architectures', fontsize=16)\n",
    "ax1.set_xlabel('Epochs', fontsize=12)\n",
    "ax1.set_ylabel('BCEWithLogitsLoss', fontsize=12)\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 3. PLOT PERFORMANCE BAR CHART ---\n",
    "final_metrics = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'F1-Score': [],\n",
    "    'Precision': [],\n",
    "    'Recall': []\n",
    "}\n",
    "\n",
    "for model_name, history in results.items():\n",
    "    final_metrics['Model'].append(model_name)\n",
    "    final_metrics['Accuracy'].append(history['val_accuracy'][-1])\n",
    "    final_metrics['F1-Score'].append(history['val_f1'][-1]) # Get the last epoch's score\n",
    "    final_metrics['Precision'].append(history['val_precision'][-1])\n",
    "    final_metrics['Recall'].append(history['val_recall'][-1])\n",
    "\n",
    "metrics_df = pd.DataFrame(final_metrics)\n",
    "\n",
    "fig, ax2 = plt.subplots(1, 1, figsize=(12, 7))\n",
    "metrics_df.plot(x='Model', y=['Accuracy', 'F1-Score', 'Precision', 'Recall'], kind='bar', ax=ax2, zorder=3)\n",
    "\n",
    "ax2.set_title('Final Performance Metrics Comparison', fontsize=16)\n",
    "ax2.set_ylabel('Score', fontsize=12)\n",
    "ax2.set_xlabel('ResNet Architecture', fontsize=12)\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "ax2.grid(axis='y', zorder=0)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for p in ax2.patches:\n",
    "    ax2.annotate(f\"{p.get_height():.3f}\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', xytext=(0, 9), textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
